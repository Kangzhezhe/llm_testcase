"""
æµ‹è¯•é›†æˆMCPæ”¯æŒçš„LLMç±»
"""
import asyncio
import sys
import os
import pytest


from ..llm import LLM, create_llm_with_mcp
from ..tool_call import LLMToolCaller

# å°è¯•å¯¼å…¥MCPç›¸å…³æ¨¡å—
try:
    from ..mcp_client import MCPServerConfig, MCPTransportType, MCP_AVAILABLE
except ImportError:
    MCP_AVAILABLE = False


class TestLLMIntegration:
    """LLMé›†æˆæµ‹è¯•ç±»"""
    
    def test_traditional_tools(self):
        """æµ‹è¯•ä¼ ç»Ÿå·¥å…·è°ƒç”¨"""
        print("=== æµ‹è¯•ä¼ ç»Ÿå·¥å…·è°ƒç”¨ ===")
        
        # å®šä¹‰å·¥å…·å‡½æ•°
        def add(a: float, b: float) -> float:
            """åŠ æ³•å·¥å…·"""
            return a + b

        def multiply(a: float, b: float) -> float:
            """ä¹˜æ³•å·¥å…·"""
            return a * b

        def echo(text: str) -> str:
            """å›å£°å·¥å…·"""
            return f"å›å£°: {text}"

        # åˆ›å»ºä¼ ç»Ÿå·¥å…·è°ƒç”¨å™¨
        traditional_caller = LLMToolCaller([add, multiply, echo])
        
        # åˆ›å»ºLLMå®ä¾‹
        llm = LLM()
        
        # æµ‹è¯•ä¼ ç»Ÿå·¥å…·è°ƒç”¨
        print("\n--- æµ‹è¯•åŠ æ³• ---")
        result1 = llm.call("è¯·å¸®æˆ‘è®¡ç®— 3 + 5", caller=traditional_caller)
        print(f"ç»“æœ: {result1}")
        assert result1 is not None
        assert isinstance(result1, dict)
        assert "tool_name" in result1
        assert "tool_result" in result1
        assert result1["tool_name"] == "add"
        assert result1["tool_result"] == 8.0
        
        print("\n--- æµ‹è¯•ä¹˜æ³• ---")
        result2 = llm.call("è¯·å¸®æˆ‘è®¡ç®— 4 Ã— 6", caller=traditional_caller)
        print(f"ç»“æœ: {result2}")
        assert result2 is not None
        assert isinstance(result2, dict)
        assert "tool_name" in result2
        assert "tool_result" in result2
        assert result2["tool_name"] == "multiply"
        assert result2["tool_result"] == 24.0
        
        print("\n--- æµ‹è¯•å›å£° ---")
        result3 = llm.call("è¯·é‡å¤è¯´ 'Hello World'", caller=traditional_caller)
        print(f"ç»“æœ: {result3}")
        assert result3 is not None
        # å›å£°å·¥å…·å¯èƒ½ç›´æ¥è¿”å›å­—ç¬¦ä¸²æˆ–åŒ…å«å·¥å…·è°ƒç”¨ä¿¡æ¯çš„å­—å…¸
        if isinstance(result3, dict):
            assert "tool_name" in result3
            assert "tool_result" in result3
            assert result3["tool_name"] == "echo"
            assert "Hello World" in str(result3["tool_result"])
        else:
            assert "Hello World" in str(result3)

    @pytest.mark.asyncio
    async def test_mcp_tools(self):
        """æµ‹è¯•MCPå·¥å…·è°ƒç”¨"""
        if not MCP_AVAILABLE:
            pytest.skip("MCPåŠŸèƒ½ä¸å¯ç”¨ï¼Œè·³è¿‡æµ‹è¯•")
        
        print("=== æµ‹è¯•MCPå·¥å…·è°ƒç”¨ ===")
        
        # åˆ›å»ºMCPé…ç½®
        mcp_configs = [
            MCPServerConfig(
                name="demo",
                command="python",
                args=["-m", "src.core.llm.demo.demo_mcp_server"],
                transport=MCPTransportType.STDIO
            )
        ]
        
        # åˆ›å»ºæ”¯æŒMCPçš„LLM
        llm = create_llm_with_mcp(mcp_configs)
        
        try:
            # åˆå§‹åŒ–MCPè¿æ¥
            print("åˆå§‹åŒ–MCPè¿æ¥...")
            await llm.init_mcp()
            
            # è·å–å¯ç”¨å·¥å…·
            tools = llm.get_available_tools("mcp")
            print(f"å¯ç”¨çš„MCPå·¥å…·: {tools}")
            
            # æµ‹è¯•MCPå·¥å…·è°ƒç”¨
            print("\n--- æµ‹è¯•MCPè®¡ç®—å·¥å…· ---")
            result1 = await llm.call_async("è¯·ä½¿ç”¨calculateå·¥å…·è®¡ç®— 10 + 20", use_mcp=True)
            print(f"ç»“æœ: {result1}")
            assert result1 is not None
            assert isinstance(result1, dict)
            assert "tool_name" in result1
            assert "tool_result" in result1
            # éªŒè¯å·¥å…·è°ƒç”¨æˆåŠŸ
            tool_result = result1["tool_result"]
            if hasattr(tool_result, 'data'):
                assert tool_result.data == 30.0
            elif hasattr(tool_result, 'structured_content'):
                assert tool_result.structured_content.get('result') == 30.0
            
            print("\n--- æµ‹è¯•è·å–æ—¶é—´ ---")
            result2 = await llm.call_async("è¯·è·å–å½“å‰æ—¶é—´", use_mcp=True)
            print(f"ç»“æœ: {result2}")
            assert result2 is not None
            assert isinstance(result2, dict)
            assert "tool_name" in result2
            assert "tool_result" in result2
            # éªŒè¯æ—¶é—´æ ¼å¼ï¼ˆYYYY-MM-DD HH:MM:SSï¼‰
            tool_result2 = result2["tool_result"]
            if hasattr(tool_result2, 'data'):
                time_str = tool_result2.data
            elif hasattr(tool_result2, 'structured_content'):
                time_str = tool_result2.structured_content.get('result', '')
            else:
                time_str = str(tool_result2)
            assert len(time_str) >= 19  # è‡³å°‘åŒ…å«æ—¥æœŸæ—¶é—´æ ¼å¼
            assert "2025" in time_str
            
            print("\n--- æµ‹è¯•å›å£°æ¶ˆæ¯ ---")
            result3 = await llm.call_async("è¯·ä½¿ç”¨echo_messageå·¥å…·é‡å¤'MCPæµ‹è¯•æˆåŠŸ'", use_mcp=True)
            print(f"ç»“æœ: {result3}")
            assert result3 is not None
            assert isinstance(result3, dict)
            assert "tool_name" in result3
            assert "tool_result" in result3
            # éªŒè¯å›å£°å†…å®¹
            tool_result3 = result3["tool_result"]
            if hasattr(tool_result3, 'data'):
                echo_str = tool_result3.data
            elif hasattr(tool_result3, 'structured_content'):
                echo_str = tool_result3.structured_content.get('result', '')
            else:
                echo_str = str(tool_result3)
            assert "MCPæµ‹è¯•æˆåŠŸ" in echo_str
            
        except Exception as e:
            print(f"MCPæµ‹è¯•å‡ºé”™: {e}")
            pytest.fail(f"MCPæµ‹è¯•å¤±è´¥: {e}")
        finally:
            # æ¸…ç†MCPè¿æ¥
            await llm.cleanup_mcp()

    @pytest.mark.asyncio
    async def test_mixed_usage(self):
        """æµ‹è¯•æ··åˆä½¿ç”¨ä¼ ç»Ÿå·¥å…·å’ŒMCPå·¥å…·"""
        if not MCP_AVAILABLE:
            pytest.skip("MCPåŠŸèƒ½ä¸å¯ç”¨ï¼Œè·³è¿‡æ··åˆæµ‹è¯•")
        
        print("=== æµ‹è¯•æ··åˆä½¿ç”¨ ===")
        
        # å®šä¹‰ä¼ ç»Ÿå·¥å…·
        def add(a: float, b: float) -> float:
            return a + b
        
        traditional_caller = LLMToolCaller([add])
        
        # åˆ›å»ºMCPé…ç½®
        mcp_configs = [
            MCPServerConfig(
                name="demo",
                command="python",
                args=["-m", "src.core.llm.demo.demo_mcp_server"],
                transport=MCPTransportType.STDIO
            )
        ]
        
        llm = LLM(mcp_configs=mcp_configs)
        
        try:
            await llm.init_mcp()
            
            print("\n--- ä½¿ç”¨ä¼ ç»Ÿå·¥å…· ---")
            result1 = llm.call("è¯·è®¡ç®— 5 + 3", caller=traditional_caller, use_mcp=False)
            print(f"ä¼ ç»Ÿå·¥å…·ç»“æœ: {result1}")
            assert result1 is not None

            result1_async = await llm.call_async("è¯·è®¡ç®— 5 + 3", caller=traditional_caller, use_mcp=False)
            print(f"ä¼ ç»Ÿå·¥å…·å¼‚æ­¥ç»“æœ: {result1_async}")
            assert result1_async is not None
            
            print("\n--- ä½¿ç”¨MCPå·¥å…· ---")
            result2 = await llm.call_async("è¯·è·å–å½“å‰æ—¶é—´", use_mcp=True)
            print(f"MCPå·¥å…·ç»“æœ: {result2}")
            assert result2 is not None
            
            print("\n--- æ™®é€šå¯¹è¯ï¼ˆä¸ä½¿ç”¨å·¥å…·ï¼‰ ---")
            result3 = llm.call("ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±")
            print(f"æ™®é€šå¯¹è¯ç»“æœ: {result3}")
            assert result3 is not None
            
        except Exception as e:
            pytest.fail(f"æ··åˆä½¿ç”¨æµ‹è¯•å¤±è´¥: {e}")
        finally:
            await llm.cleanup_mcp()

    @pytest.mark.asyncio
    async def test_parallel_async_calls(self):
        """æµ‹è¯•å¹¶è¡Œå¼‚æ­¥è°ƒç”¨"""
        if not MCP_AVAILABLE:
            pytest.skip("MCPåŠŸèƒ½ä¸å¯ç”¨ï¼Œè·³è¿‡å¹¶è¡Œæµ‹è¯•")
        
        print("=== æµ‹è¯•å¹¶è¡Œå¼‚æ­¥è°ƒç”¨ ===")
        
        # å®šä¹‰ä¼ ç»Ÿå·¥å…·
        def add(a: float, b: float) -> float:
            return a + b
        
        def multiply(a: float, b: float) -> float:
            return a * b
        
        traditional_caller = LLMToolCaller([add, multiply])
        
        # åˆ›å»ºMCPé…ç½®
        mcp_configs = [
            MCPServerConfig(
                name="demo",
                command="python",
                args=["-m", "src.core.llm.demo.demo_mcp_server"],
                transport=MCPTransportType.STDIO
            )
        ]
        
        llm = LLM(mcp_configs=mcp_configs)
        
        try:
            await llm.init_mcp()
            
            print("\n--- å¹¶è¡Œè°ƒç”¨å¤šä¸ªä¼ ç»Ÿå·¥å…· ---")
            # å¹¶è¡Œè°ƒç”¨å¤šä¸ªä¼ ç»Ÿå·¥å…·
            task1 = llm.call_async("è¯·ç”¨å·¥å…·è®¡ç®— 10 + 20", caller=traditional_caller, use_mcp=False)
            task2 = llm.call_async("è¯·ç”¨å·¥å…·è®¡ç®— 5 Ã— 6", caller=traditional_caller, use_mcp=False)
            task3 = llm.call_async("è¯·ç”¨å·¥å…·è®¡ç®— 100 + 200", caller=traditional_caller, use_mcp=False)
            
            # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
            results = await asyncio.gather(task1, task2, task3)
            
            print(f"å¹¶è¡Œä¼ ç»Ÿå·¥å…·ç»“æœ: {results}")
            assert len(results) == 3
            for result in results:
                assert "tool_name" in result
                assert "tool_result" in result
            
            print("\n--- å¹¶è¡Œè°ƒç”¨å¤šä¸ªMCPå·¥å…· ---")
            # å¹¶è¡Œè°ƒç”¨å¤šä¸ªMCPå·¥å…·
            mcp_task1 = llm.call_async("è¯·ä½¿ç”¨calculateå·¥å…·è®¡ç®— 15 + 25", use_mcp=True)
            mcp_task2 = llm.call_async("è¯·è·å–å½“å‰æ—¶é—´", use_mcp=True)
            mcp_task3 = llm.call_async("è¯·ä½¿ç”¨echo_messageå·¥å…·é‡å¤'å¹¶è¡Œæµ‹è¯•'", use_mcp=True)
            
            # ç­‰å¾…æ‰€æœ‰MCPä»»åŠ¡å®Œæˆ
            mcp_results = await asyncio.gather(mcp_task1, mcp_task2, mcp_task3)
            
            print(f"å¹¶è¡ŒMCPå·¥å…·ç»“æœ: {mcp_results}")
            assert len(mcp_results) == 3
            for result in mcp_results:
                assert "tool_name" in result
                assert "tool_result" in result
            
            print("\n--- æ··åˆå¹¶è¡Œè°ƒç”¨ï¼ˆä¼ ç»Ÿå·¥å…· + MCPå·¥å…· + æ™®é€šå¯¹è¯ï¼‰ ---")
            # æ··åˆå¹¶è¡Œè°ƒç”¨
            mixed_task1 = llm.call_async("è¯·ç”¨å·¥å…·è®¡ç®— 7 + 8", caller=traditional_caller, use_mcp=False)
            mixed_task2 = llm.call_async("è¯·è·å–å½“å‰æ—¶é—´", use_mcp=True)
            # æ³¨æ„ï¼šæ™®é€šå¯¹è¯éœ€è¦ç”¨åŒæ­¥æ–¹å¼åŒ…è£…æˆå¼‚æ­¥
            mixed_task3 = asyncio.create_task(asyncio.to_thread(llm.call, "è¯·ç®€å•ä»‹ç»ä¸€ä¸‹Python"))
            
            # ç­‰å¾…æ‰€æœ‰æ··åˆä»»åŠ¡å®Œæˆ
            mixed_results = await asyncio.gather(mixed_task1, mixed_task2, mixed_task3)
            
            print(f"æ··åˆå¹¶è¡Œç»“æœ: {mixed_results}")
            assert len(mixed_results) == 3
            # éªŒè¯ä¼ ç»Ÿå·¥å…·ç»“æœ
            assert "tool_name" in mixed_results[0]
            assert "tool_result" in mixed_results[0]
            # éªŒè¯MCPå·¥å…·ç»“æœ
            assert "tool_name" in mixed_results[1]
            assert "tool_result" in mixed_results[1]
            # éªŒè¯æ™®é€šå¯¹è¯ç»“æœ
            assert mixed_results[2] is not None
            assert isinstance(mixed_results[2], str)

        except Exception as e:
            pytest.fail(f"å¹¶è¡Œå¼‚æ­¥è°ƒç”¨æµ‹è¯•å¤±è´¥: {e}")
        finally:
            await llm.cleanup_mcp()

    @pytest.mark.asyncio
    async def test_concurrent_performance(self):
        """ä¸“é—¨æµ‹è¯•å¹¶å‘æ€§èƒ½çš„ç”¨ä¾‹"""
        import os
        if not os.getenv('RUN_PERFORMANCE_TESTS', False):
            print("æ€§èƒ½æµ‹è¯•é»˜è®¤è·³è¿‡ï¼Œè®¾ç½®ç¯å¢ƒå˜é‡ RUN_PERFORMANCE_TESTS=1 æ¥è¿è¡Œ")
            return
    

        if not MCP_AVAILABLE:
            pytest.skip("MCPåŠŸèƒ½ä¸å¯ç”¨ï¼Œè·³è¿‡å¹¶å‘æ€§èƒ½æµ‹è¯•")
        
        print("=== ä¸“é—¨æµ‹è¯•å¹¶å‘æ€§èƒ½ ===")
        
        # åˆ›å»ºMCPé…ç½®
        mcp_configs = [
            MCPServerConfig(
                name="demo",
                command="python",
                args=["-m", "src.core.llm.demo.demo_mcp_server"],
                transport=MCPTransportType.STDIO
            )
        ]
        
        llm = LLM(mcp_configs=mcp_configs)
        
        try:
            await llm.init_mcp()
            
            import time
            
            # æµ‹è¯•ä¸åŒå¹¶å‘æ•°é‡çš„æ€§èƒ½
            concurrent_levels = [1, 2, 5, 10, 20]
            performance_results = {}
            
            for num_calls in concurrent_levels:
                print(f"\n{'='*60}")
                print(f"æµ‹è¯•å¹¶å‘æ•°é‡: {num_calls}")
                print(f"{'='*60}")
                
                # ä¸²è¡Œæ‰§è¡ŒåŸºå‡†æµ‹è¯•
                print(f"\n--- ä¸²è¡Œæ‰§è¡Œ {num_calls} ä¸ªè°ƒç”¨ï¼ˆåŸºå‡†æµ‹è¯•ï¼‰ ---")
                start_time = time.time()
                
                serial_results = []
                for i in range(num_calls):
                    task_type = i % 4
                    if task_type == 0:
                        result = await llm.call_async("è¯·è·å–å½“å‰æ—¶é—´", use_mcp=True)
                    elif task_type == 1:
                        result = await llm.call_async(f"è¯·ä½¿ç”¨echo_messageå·¥å…·é‡å¤'ä¸²è¡Œ{i}'", use_mcp=True)
                    elif task_type == 2:
                        result = await llm.call_async(f"è¯·ä½¿ç”¨calculateå·¥å…·è®¡ç®— {i*5} + {i*3}", use_mcp=True)
                    else:
                        result = await llm.call_async("è¯·è·å–å½“å‰æ—¶é—´", use_mcp=True)
                    serial_results.append(result)
                
                serial_time = time.time() - start_time
                print(f"ä¸²è¡Œæ‰§è¡Œæ—¶é—´: {serial_time:.3f}ç§’")
                print(f"å¹³å‡æ¯ä¸ªè°ƒç”¨: {(serial_time / num_calls):.3f}ç§’")
                
                # å¹¶è¡Œæ‰§è¡Œæµ‹è¯•
                print(f"\n--- å¹¶è¡Œæ‰§è¡Œ {num_calls} ä¸ªè°ƒç”¨ ---")
                start_time = time.time()
                
                parallel_tasks = []
                for i in range(num_calls):
                    task_type = i % 4
                    if task_type == 0:
                        task = llm.call_async("è¯·è·å–å½“å‰æ—¶é—´", use_mcp=True)
                    elif task_type == 1:
                        task = llm.call_async(f"è¯·ä½¿ç”¨echo_messageå·¥å…·é‡å¤'å¹¶è¡Œ{i}'", use_mcp=True)
                    elif task_type == 2:
                        task = llm.call_async(f"è¯·ä½¿ç”¨calculateå·¥å…·è®¡ç®— {i*5} + {i*3}", use_mcp=True)
                    else:
                        task = llm.call_async("è¯·è·å–å½“å‰æ—¶é—´", use_mcp=True)
                    parallel_tasks.append(task)
                
                parallel_results = await asyncio.gather(*parallel_tasks, return_exceptions=True)
                parallel_time = time.time() - start_time
                
                # ç»Ÿè®¡æˆåŠŸå’Œå¤±è´¥
                success_count = 0
                error_count = 0
                for result in parallel_results:
                    if isinstance(result, Exception):
                        error_count += 1
                        print(f"é”™è¯¯: {result}")
                    elif isinstance(result, dict) and "tool_name" in result:
                        success_count += 1
                    else:
                        error_count += 1
                
                print(f"å¹¶è¡Œæ‰§è¡Œæ—¶é—´: {parallel_time:.3f}ç§’")
                print(f"å¹³å‡æ¯ä¸ªè°ƒç”¨: {(parallel_time / num_calls):.3f}ç§’")
                print(f"æˆåŠŸè°ƒç”¨: {success_count}/{num_calls} ({(success_count/num_calls*100):.1f}%)")
                print(f"å¤±è´¥è°ƒç”¨: {error_count}/{num_calls} ({(error_count/num_calls*100):.1f}%)")
                
                # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
                if parallel_time > 0 and success_count > 0:
                    speedup = serial_time / parallel_time
                    efficiency = speedup / num_calls * 100
                    throughput_serial = num_calls / serial_time
                    throughput_parallel = success_count / parallel_time
                    
                    print(f"\n--- æ€§èƒ½æŒ‡æ ‡ ---")
                    print(f"åŠ é€Ÿæ¯”: {speedup:.2f}x")
                    print(f"å¹¶è¡Œæ•ˆç‡: {efficiency:.1f}%")
                    print(f"ä¸²è¡Œååé‡: {throughput_serial:.2f} è°ƒç”¨/ç§’")
                    print(f"å¹¶è¡Œååé‡: {throughput_parallel:.2f} è°ƒç”¨/ç§’")
                    print(f"ååé‡æå‡: {(throughput_parallel/throughput_serial):.2f}x")
                    
                    # ä¿å­˜ç»“æœç”¨äºæœ€ç»ˆåˆ†æ
                    performance_results[num_calls] = {
                        'serial_time': serial_time,
                        'parallel_time': parallel_time,
                        'speedup': speedup,
                        'efficiency': efficiency,
                        'success_rate': success_count / num_calls,
                        'throughput_improvement': throughput_parallel / throughput_serial
                    }
                    
                    # æ€§èƒ½è¯„ä¼°
                    if efficiency >= 70:
                        print(f"ğŸŸ¢ æ€§èƒ½è¯„çº§: ä¼˜ç§€ (æ•ˆç‡ {efficiency:.1f}%)")
                    elif efficiency >= 50:
                        print(f"ğŸŸ¡ æ€§èƒ½è¯„çº§: è‰¯å¥½ (æ•ˆç‡ {efficiency:.1f}%)")
                    elif efficiency >= 30:
                        print(f"ğŸŸ  æ€§èƒ½è¯„çº§: ä¸€èˆ¬ (æ•ˆç‡ {efficiency:.1f}%)")
                    else:
                        print(f"ğŸ”´ æ€§èƒ½è¯„çº§: è¾ƒå·® (æ•ˆç‡ {efficiency:.1f}%)")
                
                # ç¨å¾®ç­‰å¾…ä¸€ä¸‹ï¼Œé¿å…èµ„æºç«äº‰
                await asyncio.sleep(0.5)
            
            # æœ€ç»ˆæ€§èƒ½åˆ†ææŠ¥å‘Š
            print(f"\n{'='*80}")
            print("å¹¶å‘æ€§èƒ½åˆ†ææŠ¥å‘Š")
            print(f"{'='*80}")
            
            print(f"{'å¹¶å‘æ•°':<8} {'ä¸²è¡Œæ—¶é—´':<10} {'å¹¶è¡Œæ—¶é—´':<10} {'åŠ é€Ÿæ¯”':<8} {'æ•ˆç‡':<8} {'æˆåŠŸç‡':<8} {'ååé‡æå‡':<10}")
            print("-" * 80)
            
            for num_calls, metrics in performance_results.items():
                print(f"{num_calls:<8} "
                    f"{metrics['serial_time']:<10.3f} "
                    f"{metrics['parallel_time']:<10.3f} "
                    f"{metrics['speedup']:<8.2f} "
                    f"{metrics['efficiency']:<8.1f}% "
                    f"{metrics['success_rate']:<8.1f}% "
                    f"{metrics['throughput_improvement']:<10.2f}x")
            
            # å¯»æ‰¾æœ€ä¼˜å¹¶å‘æ•°
            if performance_results:
                best_efficiency = max(performance_results.items(), 
                                    key=lambda x: x[1]['efficiency'])
                best_throughput = max(performance_results.items(), 
                                    key=lambda x: x[1]['throughput_improvement'])
                
                print(f"\nğŸ“Š æ€§èƒ½åˆ†æ:")
                print(f"â€¢ æœ€é«˜æ•ˆç‡: å¹¶å‘æ•° {best_efficiency[0]} (æ•ˆç‡ {best_efficiency[1]['efficiency']:.1f}%)")
                print(f"â€¢ æœ€é«˜ååé‡: å¹¶å‘æ•° {best_throughput[0]} (æå‡ {best_throughput[1]['throughput_improvement']:.2f}x)")
                
                # æ€§èƒ½ç“¶é¢ˆåˆ†æ
                print(f"\nğŸ” ç“¶é¢ˆåˆ†æ:")
                high_concurrency = [k for k, v in performance_results.items() 
                                if k >= 10 and v['efficiency'] < 30]
                if high_concurrency:
                    print(f"â€¢ é«˜å¹¶å‘æ€§èƒ½ä¸‹é™: å¹¶å‘æ•° {high_concurrency} æ—¶æ•ˆç‡æ˜¾è‘—ä¸‹é™")
                    print(f"â€¢ å¯èƒ½åŸå› : MCPè¿æ¥æ± é™åˆ¶ã€æœåŠ¡å™¨å¤„ç†èƒ½åŠ›ç“¶é¢ˆ")
                
                low_speedup = [k for k, v in performance_results.items() 
                            if v['speedup'] < 1.5]
                if low_speedup:
                    print(f"â€¢ å¹¶è¡ŒåŠ é€Ÿä¸æ˜æ˜¾: å¹¶å‘æ•° {low_speedup} æ—¶åŠ é€Ÿæ¯” < 1.5x")
                    print(f"â€¢ å¯èƒ½åŸå› : é”ç«äº‰ã€åŒæ­¥I/Oã€ç½‘ç»œå»¶è¿Ÿ")
                
                success_issues = [k for k, v in performance_results.items() 
                                if v['success_rate'] < 0.95]
                if success_issues:
                    print(f"â€¢ ç¨³å®šæ€§é—®é¢˜: å¹¶å‘æ•° {success_issues} æ—¶æˆåŠŸç‡ < 95%")
                    print(f"â€¢ å»ºè®®: é™ä½å¹¶å‘æ•°æˆ–å¢åŠ é‡è¯•æœºåˆ¶")
            
            # ç»™å‡ºä¼˜åŒ–å»ºè®®
            print(f"\nğŸ’¡ ä¼˜åŒ–å»ºè®®:")
            if best_efficiency[1]['efficiency'] >= 70:
                print(f"â€¢ ç³»ç»Ÿå¹¶å‘æ€§èƒ½è‰¯å¥½ï¼Œæ¨èå¹¶å‘æ•°: {best_efficiency[0]}")
            elif best_efficiency[1]['efficiency'] >= 50:
                print(f"â€¢ ç³»ç»Ÿå¹¶å‘æ€§èƒ½ä¸­ç­‰ï¼Œå¯ä½¿ç”¨å¹¶å‘æ•°: {best_efficiency[0]}ï¼Œä½†æœ‰ä¼˜åŒ–ç©ºé—´")
                print(f"â€¢ å»ºè®®: æ£€æŸ¥MCPè¿æ¥æ± è®¾ç½®ã€ä¼˜åŒ–ç½‘ç»œå»¶è¿Ÿ")
            else:
                print(f"â€¢ ç³»ç»Ÿå¹¶å‘æ€§èƒ½è¾ƒå·®ï¼Œå»ºè®®:")
                print(f"  - ä½¿ç”¨è¾ƒä½å¹¶å‘æ•° (â‰¤ 5)")
                print(f"  - æ£€æŸ¥æ˜¯å¦å­˜åœ¨å…¨å±€é”")
                print(f"  - è€ƒè™‘ä½¿ç”¨è¿æ¥æ± æˆ–å¤šå®ä¾‹")
                print(f"  - ä¼˜åŒ–LLM APIè°ƒç”¨æ€§èƒ½")

            # æ–­è¨€éªŒè¯
            assert len(performance_results) > 0, "åº”è¯¥è‡³å°‘å®Œæˆä¸€ä¸ªå¹¶å‘çº§åˆ«çš„æµ‹è¯•"
            
            # éªŒè¯åŸºæœ¬çš„å¹¶å‘èƒ½åŠ›
            if 5 in performance_results:
                assert performance_results[5]['success_rate'] >= 0.8, "å¹¶å‘æ•°5æ—¶æˆåŠŸç‡åº”è¯¥ >= 80%"
                assert performance_results[5]['speedup'] >= 1.2, "å¹¶å‘æ•°5æ—¶åº”è¯¥æœ‰è‡³å°‘1.2xçš„åŠ é€Ÿ"
                    
        except Exception as e:
            pytest.fail(f"å¹¶å‘æ€§èƒ½æµ‹è¯•å¤±è´¥: {e}")
        finally:
            await llm.cleanup_mcp()


@pytest.mark.asyncio
async def test_concurrent_performance():
    """å¹¶å‘æ€§èƒ½æµ‹è¯•ï¼ˆå‡½æ•°å½¢å¼ï¼‰"""
    test_instance = TestLLMIntegration()
    await test_instance.test_concurrent_performance()

# ä¸ºäº†ä¿æŒå‘åå…¼å®¹ï¼Œä¿ç•™åŸæ¥çš„å‡½æ•°å½¢å¼
def test_traditional_tools():
    """æµ‹è¯•ä¼ ç»Ÿå·¥å…·è°ƒç”¨ï¼ˆå‡½æ•°å½¢å¼ï¼‰"""
    test_instance = TestLLMIntegration()
    test_instance.test_traditional_tools()


@pytest.mark.asyncio
async def test_mcp_tools():
    """æµ‹è¯•MCPå·¥å…·è°ƒç”¨ï¼ˆå‡½æ•°å½¢å¼ï¼‰"""
    test_instance = TestLLMIntegration()
    await test_instance.test_mcp_tools()


@pytest.mark.asyncio
async def test_mixed_usage():
    """æµ‹è¯•æ··åˆä½¿ç”¨ï¼ˆå‡½æ•°å½¢å¼ï¼‰"""
    test_instance = TestLLMIntegration()
    await test_instance.test_mixed_usage()


@pytest.mark.asyncio
async def test_parallel_async_calls():
    """æµ‹è¯•å¹¶è¡Œå¼‚æ­¥è°ƒç”¨ï¼ˆå‡½æ•°å½¢å¼ï¼‰"""
    test_instance = TestLLMIntegration()
    await test_instance.test_parallel_async_calls()


# æ‰‹åŠ¨è¿è¡Œè„šæœ¬æ—¶çš„ä¸»å‡½æ•°
async def main():
    """ä¸»æµ‹è¯•å‡½æ•°ï¼ˆæ‰‹åŠ¨è¿è¡Œæ—¶ä½¿ç”¨ï¼‰"""
    print("å¼€å§‹æµ‹è¯•é›†æˆMCPæ”¯æŒçš„LLMç±»")
    print("=" * 50)
    
    # åˆ›å»ºæµ‹è¯•å®ä¾‹
    test_instance = TestLLMIntegration()
    
    # æµ‹è¯•ä¼ ç»Ÿå·¥å…·
    test_instance.test_traditional_tools()
    
    print("\n" + "=" * 50)
    
    # æµ‹è¯•MCPå·¥å…·
    await test_instance.test_mcp_tools()
    
    print("\n" + "=" * 50)
    
    # æµ‹è¯•æ··åˆä½¿ç”¨
    await test_instance.test_mixed_usage()
    
    print("\n" + "=" * 50)
    
    # æµ‹è¯•å¹¶è¡Œå¼‚æ­¥è°ƒç”¨
    await test_instance.test_parallel_async_calls()
    
    print("\n" + "=" * 50)
    
     # ä¸“é—¨çš„å¹¶å‘æ€§èƒ½æµ‹è¯•
    await test_instance.test_concurrent_performance()
    print("\n" + "=" * 50)
    print("æ‰€æœ‰æµ‹è¯•å®Œæˆï¼")


if __name__ == "__main__":
    # æ‰‹åŠ¨è¿è¡Œæ—¶ä½¿ç”¨å¼‚æ­¥
    asyncio.run(main())