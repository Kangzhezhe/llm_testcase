"""
MCPå®Œæ•´æ¼”ç¤ºè„šæœ¬
å±•ç¤ºå¦‚ä½•ä½¿ç”¨MCPæœåŠ¡å™¨å’Œå®¢æˆ·ç«¯
"""
import asyncio
import json
import time
from pathlib import Path
import sys

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(str(Path(__file__).parent.parent.parent))

from src.core.simple_mcp import (
    MCPLLMServer, 
    MCPLLMClient, 
    MCPClientManager,
    MCPConfig,
    MCPServerLauncher,
    create_default_tools
)
from src.core.llm.llm import LLM

async def demo_basic_mcp():
    """åŸºç¡€MCPåŠŸèƒ½æ¼”ç¤º"""
    print("=== åŸºç¡€MCPåŠŸèƒ½æ¼”ç¤º ===\n")
    
    # 1. åˆ›å»ºé…ç½®
    print("1. åˆ›å»ºMCPé…ç½®...")
    config = MCPConfig("demo_config.json")
    
    # æ·»åŠ ç¤ºä¾‹çŸ¥è¯†åº“é…ç½®
    file_list = [
        {"file_path": "data/ç½‘æ˜“äº‘éŸ³ä¹PRD.md", "type": "äº§å“æ–‡æ¡£"},
        {"file_path": "data/testcase.md", "type": "æµ‹è¯•ç”¨ä¾‹"}
    ]
    config.add_knowledge_base("demo_kb", file_list, max_len=1000, overlap=100)
    
    print("   é…ç½®åˆ›å»ºå®Œæˆ")
    
    # 2. åˆ›å»ºæœåŠ¡å™¨
    print("2. åˆ›å»ºMCPæœåŠ¡å™¨...")
    launcher = MCPServerLauncher(config)
    launcher.register_custom_tools()
    
    # åˆ›å»ºLLMå®ä¾‹
    llm = LLM()
    
    # å°è¯•æ„å»ºçŸ¥è¯†åº“
    try:
        llm.build_knowledge_base(file_list, collection_name="demo_kb")
        print("   çŸ¥è¯†åº“æ„å»ºæˆåŠŸ")
    except Exception as e:
        print(f"   çŸ¥è¯†åº“æ„å»ºå¤±è´¥: {e}")
    
    # åˆ›å»ºæœåŠ¡å™¨å®ä¾‹
    server = MCPLLMServer(llm)
    
    # æ³¨å†Œé¢å¤–çš„è‡ªå®šä¹‰å·¥å…·
    def fibonacci(n: int) -> int:
        """è®¡ç®—æ–æ³¢é‚£å¥‘æ•°åˆ—"""
        if n <= 1:
            return n
        return fibonacci(n-1) + fibonacci(n-2)
    
    def word_count(text: str) -> dict:
        """ç»Ÿè®¡æ–‡æœ¬ä¿¡æ¯"""
        return {
            "characters": len(text),
            "words": len(text.split()),
            "lines": len(text.split('\n'))
        }
    
    server.register_tool("fibonacci", fibonacci, "è®¡ç®—æ–æ³¢é‚£å¥‘æ•°åˆ—")
    server.register_tool("word_count", word_count, "ç»Ÿè®¡æ–‡æœ¬å­—ç¬¦ã€å•è¯å’Œè¡Œæ•°")
    
    print("   æœåŠ¡å™¨åˆ›å»ºå®Œæˆ")
    
    # 3. æµ‹è¯•å·¥å…·æ³¨å†Œ
    print("3. æµ‹è¯•å·¥å…·æ³¨å†Œ...")
    print(f"   å·²æ³¨å†Œå·¥å…·: {list(server.tools.keys())}")
    
    # 4. æ¨¡æ‹ŸMCPäº¤äº’
    print("4. æ¨¡æ‹ŸMCPäº¤äº’...")
    
    # æ¨¡æ‹Ÿåˆ—å‡ºå·¥å…·
    tools = []
    for tool_name, tool_info in server.tools.items():
        param_schema = tool_info["param_model"].model_json_schema() if hasattr(tool_info["param_model"], 'model_json_schema') else {}
        tools.append({
            "name": tool_name,
            "description": tool_info["description"],
            "schema": param_schema
        })
    
    print("   å¯ç”¨å·¥å…·:")
    for tool in tools:
        print(f"     - {tool['name']}: {tool['description']}")
    
    # æ¨¡æ‹Ÿå·¥å…·è°ƒç”¨
    print("\n   æµ‹è¯•å·¥å…·è°ƒç”¨:")
    
    # æµ‹è¯•æ•°å­¦è¿ç®—
    try:
        add_result = server.tools["add"]["func"](3.14, 2.86)
        print(f"     add(3.14, 2.86) = {add_result}")
    except Exception as e:
        print(f"     add è°ƒç”¨å¤±è´¥: {e}")
    
    # æµ‹è¯•æ–æ³¢é‚£å¥‘
    try:
        fib_result = server.tools["fibonacci"]["func"](10)
        print(f"     fibonacci(10) = {fib_result}")
    except Exception as e:
        print(f"     fibonacci è°ƒç”¨å¤±è´¥: {e}")
    
    # æµ‹è¯•æ–‡æœ¬ç»Ÿè®¡
    try:
        wc_result = server.tools["word_count"]["func"]("Hello world!\nThis is a test.")
        print(f"     word_count result = {wc_result}")
    except Exception as e:
        print(f"     word_count è°ƒç”¨å¤±è´¥: {e}")
    
    print("\nåŸºç¡€åŠŸèƒ½æ¼”ç¤ºå®Œæˆï¼")

async def demo_llm_integration():
    """LLMé›†æˆæ¼”ç¤º"""
    print("\n=== LLMé›†æˆæ¼”ç¤º ===\n")
    
    # åˆ›å»ºLLMå®ä¾‹
    llm = LLM()
    
    # 1. æ™®é€šå¯¹è¯æµ‹è¯•
    print("1. æ™®é€šå¯¹è¯æµ‹è¯•...")
    try:
        response = llm.call("ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±")
        print(f"   LLMå›å¤: {response}")
    except Exception as e:
        print(f"   å¯¹è¯å¤±è´¥: {e}")
    
    # 2. å·¥å…·è°ƒç”¨æµ‹è¯•
    print("\n2. å·¥å…·è°ƒç”¨æµ‹è¯•...")
    from src.core.llm.tool_call import LLMToolCaller
    
    def calculator(a: float, b: float, operation: str = "add") -> float:
        """å¤šåŠŸèƒ½è®¡ç®—å™¨"""
        if operation == "add":
            return a + b
        elif operation == "subtract":
            return a - b
        elif operation == "multiply":
            return a * b
        elif operation == "divide":
            return a / b if b != 0 else 0
        else:
            return 0
    
    caller = LLMToolCaller([calculator])
    
    try:
        result = llm.call("è¯·å¸®æˆ‘è®¡ç®— 15 ä¹˜ä»¥ 8", caller=caller)
        print(f"   è®¡ç®—ç»“æœ: {result}")
    except Exception as e:
        print(f"   å·¥å…·è°ƒç”¨å¤±è´¥: {e}")
    
    # 3. ç»“æ„åŒ–è¾“å‡ºæµ‹è¯•
    print("\n3. ç»“æ„åŒ–è¾“å‡ºæµ‹è¯•...")
    from src.core.llm.template_parser.template_parser import TemplateParser
    
    template = "ç»“æœ={result:float}è¯´æ˜={explanation:str}ç½®ä¿¡åº¦={confidence:float}"
    parser = TemplateParser(template)
    
    try:
        result = llm.call("è¯·è®¡ç®—åœ†å‘¨ç‡ä¹˜ä»¥3çš„ç»“æœ", parser=parser)
        print(f"   ç»“æ„åŒ–ç»“æœ: {result}")
    except Exception as e:
        print(f"   ç»“æ„åŒ–è¾“å‡ºå¤±è´¥: {e}")
    
    print("\nLLMé›†æˆæ¼”ç¤ºå®Œæˆï¼")

async def demo_performance_test():
    """æ€§èƒ½æµ‹è¯•æ¼”ç¤º"""
    print("\n=== æ€§èƒ½æµ‹è¯•æ¼”ç¤º ===\n")
    
    llm = LLM()
    
    # 1. å“åº”æ—¶é—´æµ‹è¯•
    print("1. å“åº”æ—¶é—´æµ‹è¯•...")
    
    test_queries = [
        "1+1ç­‰äºå¤šå°‘ï¼Ÿ",
        "è¯·ç”¨ä¸€å¥è¯ä»‹ç»äººå·¥æ™ºèƒ½",
        "ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ",
        "è§£é‡Šä¸€ä¸‹æ·±åº¦å­¦ä¹ çš„æ¦‚å¿µ"
    ]
    
    total_time = 0
    for i, query in enumerate(test_queries, 1):
        start_time = time.time()
        try:
            response = llm.call(query)
            end_time = time.time()
            elapsed = end_time - start_time
            total_time += elapsed
            print(f"   æŸ¥è¯¢{i}: {elapsed:.2f}ç§’ - {query[:20]}...")
        except Exception as e:
            print(f"   æŸ¥è¯¢{i}å¤±è´¥: {e}")
    
    avg_time = total_time / len(test_queries) if test_queries else 0
    print(f"   å¹³å‡å“åº”æ—¶é—´: {avg_time:.2f}ç§’")
    
    # 2. å¹¶å‘æµ‹è¯•ï¼ˆç®€åŒ–ç‰ˆï¼‰
    print("\n2. ç®€å•å¹¶å‘æµ‹è¯•...")
    
    async def single_query(query_id, query):
        start_time = time.time()
        try:
            # æ³¨æ„ï¼šè¿™é‡Œä½¿ç”¨åŒæ­¥çš„llm.callï¼Œåœ¨å®é™…åº”ç”¨ä¸­å¯èƒ½éœ€è¦å¼‚æ­¥ç‰ˆæœ¬
            response = llm.call(f"ç®€çŸ­å›ç­”: {query}")
            end_time = time.time()
            return {"id": query_id, "time": end_time - start_time, "success": True}
        except Exception as e:
            end_time = time.time()
            return {"id": query_id, "time": end_time - start_time, "success": False, "error": str(e)}
    
    concurrent_queries = [
        "ä»€ä¹ˆæ˜¯Pythonï¼Ÿ",
        "è§£é‡Šå˜é‡çš„æ¦‚å¿µ",
        "ä»€ä¹ˆæ˜¯å‡½æ•°ï¼Ÿ"
    ]
    
    # ç”±äºLLM.callæ˜¯åŒæ­¥çš„ï¼Œè¿™é‡Œåªæ˜¯æ¼”ç¤ºç»“æ„
    results = []
    for i, query in enumerate(concurrent_queries):
        result = await single_query(i, query)
        results.append(result)
    
    success_count = sum(1 for r in results if r["success"])
    avg_concurrent_time = sum(r["time"] for r in results) / len(results)
    
    print(f"   å¹¶å‘æŸ¥è¯¢æˆåŠŸç‡: {success_count}/{len(results)}")
    print(f"   å¹³å‡å¹¶å‘å“åº”æ—¶é—´: {avg_concurrent_time:.2f}ç§’")
    
    print("\næ€§èƒ½æµ‹è¯•æ¼”ç¤ºå®Œæˆï¼")

async def demo_error_handling():
    """é”™è¯¯å¤„ç†æ¼”ç¤º"""
    print("\n=== é”™è¯¯å¤„ç†æ¼”ç¤º ===\n")
    
    llm = LLM()
    
    # 1. å·¥å…·è°ƒç”¨é”™è¯¯
    print("1. å·¥å…·è°ƒç”¨é”™è¯¯å¤„ç†...")
    
    def divide_by_zero(a: float, b: float) -> float:
        """å¯èƒ½å‡ºé”™çš„é™¤æ³•"""
        return a / b  # å½“b=0æ—¶ä¼šå‡ºé”™
    
    from src.core.llm.tool_call import LLMToolCaller
    caller = LLMToolCaller([divide_by_zero])
    
    try:
        result = llm.call("è¯·è®¡ç®— 10 é™¤ä»¥ 0", caller=caller)
        print(f"   ç»“æœ: {result}")
    except Exception as e:
        print(f"   æ•è·é”™è¯¯: {e}")
    
    # 2. è§£æé”™è¯¯
    print("\n2. ç»“æ„åŒ–è§£æé”™è¯¯å¤„ç†...")
    
    from src.core.llm.template_parser.template_parser import TemplateParser
    
    # ä½¿ç”¨å¤æ‚æ¨¡æ¿æµ‹è¯•è§£æé”™è¯¯
    complex_template = "æ•°å­—={number:int}ï¼Œåˆ—è¡¨={items:json:list}ï¼Œå¯¹è±¡={data:json:dict}"
    parser = TemplateParser(complex_template)
    
    try:
        result = llm.call("è¯·éšä¾¿è¯´ç‚¹ä»€ä¹ˆ", parser=parser, max_retry=1)
        print(f"   è§£æç»“æœ: {result}")
    except Exception as e:
        print(f"   è§£æé”™è¯¯: {e}")
    

async def main():
    """ä¸»æ¼”ç¤ºå‡½æ•°"""
    print("ğŸš€ MCP (Model Context Protocol) å®Œæ•´æ¼”ç¤º")
    print("=" * 50)
    
    try:
        # è¿è¡Œå„ä¸ªæ¼”ç¤º
        await demo_basic_mcp()
        await demo_llm_integration()
        await demo_performance_test()
        await demo_error_handling()
        
        print("\n" + "=" * 50)
        print("âœ… æ‰€æœ‰æ¼”ç¤ºå®Œæˆï¼")
        
        print("\nğŸ“ ä½¿ç”¨è¯´æ˜:")
        print("1. å¯åŠ¨MCPæœåŠ¡å™¨: python -m src.core.mcp.cli server")
        print("2. è¿è¡Œå®¢æˆ·ç«¯æ¼”ç¤º: python -m src.core.mcp.cli client --demo")
        print("3. äº¤äº’å¼å®¢æˆ·ç«¯: python -m src.core.mcp.cli client --interactive")
        print("4. åˆ›å»ºé…ç½®æ–‡ä»¶: python -m src.core.mcp.cli config create --example")
        
    except KeyboardInterrupt:
        print("\n\nâŒ æ¼”ç¤ºè¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\n\nâŒ æ¼”ç¤ºè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    asyncio.run(main())
